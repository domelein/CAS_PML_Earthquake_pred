{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorarbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T21:29:58.563123Z",
     "start_time": "2019-03-11T21:29:55.622789Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umgebungsvariablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T21:30:00.105989Z",
     "start_time": "2019-03-11T21:30:00.101968Z"
    }
   },
   "outputs": [],
   "source": [
    "failure_datapath = '''D:/jupyter-notebooks/LANL_Earthquake_Prediction/failure/'''\n",
    "train_data_path = '''C:/studium/studium/CAS_PML/Projekt_Arbeit/earthquake/Daten/all/train.csv'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsdaten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T21:31:42.109278Z",
     "start_time": "2019-03-11T21:30:01.653955Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_path, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Testsegmente bestehen jeweils aus 150.000 Messpunkte. Aus diesem Grund setzten wir die Fenstergrösse auch auf 150000 Messpunkte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T21:56:18.028927Z",
     "start_time": "2019-03-11T21:56:18.022862Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_featureRow(acoustic_data, time_to_failure):\n",
    "    \n",
    "    strain_feature = []\n",
    "    time_to_failure = []\n",
    "    strain_feature.append(acoustic_data.mean())\n",
    "    strain_feature.append(acoustic_data.std())\n",
    "    strain_feature.append(acoustic_data.kurtosis())\n",
    "    strain_feature.append(acoustic_data.skew())\n",
    "    strain_feature.append(acoustic_data.min())\n",
    "    strain_feature.append(acoustic_data.max())\n",
    "    strain_feature.append(acoustic_data.quantile(0.01, interpolation='midpoint'))\n",
    "    strain_feature.append(acoustic_data.quantile(0.05,interpolation='midpoint'))\n",
    "    strain_feature.append(acoustic_data.quantile(0.95,interpolation='midpoint'))\n",
    "    strain_feature.append(acoustic_data.quantile(0.99,interpolation='midpoint'))\n",
    "    strain_feature.append(acoustic_data.abs().max())\n",
    "    strain_feature.append(acoustic_data.abs().mean())\n",
    "    strain_feature.append(acoustic_data.abs().std())\n",
    "    \n",
    "    time_to_failure.append(time_to_failure.values[-1])\n",
    "    return strain_feature, time_to_failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Fenster, mit der grösse 150000), wird durch das Trainingssignal geschoben mit einer geplanten Überlappung von 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Features(train_data,step, windows_size=150000, ):\n",
    "    init_idx = 0\n",
    "    features = np.array([], dtype=np.float64)\n",
    "    time_to_failure = np.array([], dtype=np.float64)\n",
    "\n",
    "    while (init_idx + window_size < len(train)):\n",
    "        window = train.iloc[init_idx:init_idx + window_size]\n",
    "        x_train , y_train =  generate_featureRow(window.acoustic_data,window.time_to_failure)\n",
    "        features.append(x_train)\n",
    "        time_to_failure.append(y_train)\n",
    "        init_idx += step\n",
    "\n",
    "    return featuers, time_to_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T22:09:43.815940Z",
     "start_time": "2019-03-11T22:08:15.855334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef generate_Features(train_data,step, windows_size=150000, ):\\n    init_idx = 0\\n    features = []\\n\\n    while (init_idx + window_size < len(train)):\\n        window = train.iloc[init_idx:init_idx + window_size]\\n        features.append(generate_featureRow(window.acoustic_data,window.time_to_failure))\\n        init_idx += step\\n\\n    return pd.DataFrame(features)\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def generate_Features(train_data,step, windows_size=150000, ):\n",
    "    init_idx = 0\n",
    "    features = []\n",
    "\n",
    "    while (init_idx + window_size < len(train)):\n",
    "        window = train.iloc[init_idx:init_idx + window_size]\n",
    "        features.append(generate_featureRow(window.acoustic_data,window.time_to_failure))\n",
    "        init_idx += step\n",
    "\n",
    "    return pd.DataFrame(features)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-11T22:13:54.874949Z",
     "start_time": "2019-03-11T22:13:54.870889Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-b54bbcb34467>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m150000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_to_failure\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mgenerate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-6a2e6fdde1e5>\u001b[0m in \u001b[0;36mgenerate_features\u001b[1;34m(acoustic_data, time_to_failure)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mstrain_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macoustic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mstrain_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_to_failure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrain_feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "step = int(0.9*150000)\n",
    "features, time_to_failure  = generate_features(train_data,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_to_failure' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-34e2de90ea66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtime_to_failure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'time_to_failure' is not defined"
     ]
    }
   ],
   "source": [
    "time_to_failure.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Model selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modell\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForrest and GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', GradientBoostingRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier': [GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,\n",
    "      max_depth=1, random_state=0, loss='ls')], 'preprocessing': [None],\n",
    "     'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "     'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    {'classifier': [RandomForestRegressor(n_estimators=100,min_samples_split=30,max_features=13)],\n",
    "     'preprocessing': [None]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-209c0e0143e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[0;32m      2\u001b[0m     cancer.data, cancer.target, random_state=0)\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_absolute_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='mean_absolute_error', cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
