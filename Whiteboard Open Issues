# Whiteboard mit offenen Punkten

Aktueller Stand:
- Librosa Library angewendet und noch mehr features generiert --> 94 features
- verschiedene Modelle angwendet:(alles Regressionsmodelle): SVR, SGD-Regression, RandomForest-Regression, GBM-Regression, CBM-Regression, Feed Forward)
- Convolutional Network steht auf der Kippe (Freq-Time-Density Spektrumbilder vorhanden)
- Entwicklungsumgebung (PowerPoint) leider noch ohne sacret
- Baseline zu den unterschiedlichen Modellen abgeschlossen (Word)
- die Modelle, mit den vielversprechensten Ergebnisse, werden weiter getunt. Voraussichtlich Feed Forward, CBM, GBM SVM linear
- bestes ergebnis bis anhin: MAE 1.486 mit cat boost Kaggle 
- 4 Nachkommastelle Geschichte: in unseren augen nicht so nÃ¼tzlich, da python float sowieso in double precision rechnet


Erkenntnis / Synch mit Max:
- Schwellenwerte sind bei den Bäumen beliebt --> typisch für Signale?
- MAE nicht unbedingt als Loss-Function geeignet (FFN) outliers herausnehmen? --> letztes Mal mit 
- crossvalidation --> Bei Regression nicht autom. Daten mischeln  
- Anzahl Features 94 vs. ca. 20? wo liegen die Unterschiede? --> Rechenzeit?
- Design FFN?


Inhalt Vortrag
- Problemstellung
- Lösungsansatz
- Modellauswahl
- Fazit/Ausblick


-crossvalidation von Regressionsmodellen -> keine stratifizierung wie bei den Classifiers! -> führte natürlich zu falschen Optimierungen --> alle Optimierungen nochmals!
Ausblick
